{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b075d001",
   "metadata": {},
   "source": [
    "Step5 â€” Filter Following Segments, Summarize, and Plot\n",
    "This notebook processes lane car-following Excel files (e.g., *following_parts*.xlsx) to:\n",
    "\n",
    "identify valid segments using centralized speed, distance, and min duration thresholds\n",
    "save per-segment row data and per-segment summary stats\n",
    "generate per-pair plots (original + filtered)\n",
    "Adjust thresholds and paths in the Parameters cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51db8761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T11:06:57.785973Z",
     "start_time": "2025-10-18T10:49:34.737235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 6 files to process.\n",
      "[1/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane-1_following_parts.xlsx\n",
      "[2/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane-2_following_parts.xlsx\n",
      "[3/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane1_following_parts.xlsx\n",
      "[4/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane2_following_parts.xlsx\n",
      "[5/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane_middle_LTR_following_parts.xlsx\n",
      "[6/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane_middle_RTL_following_parts.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================== Parameters =====================\n",
    "INPUTS = [\n",
    "    r\"/Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior\",\n",
    "]\n",
    "OUTPUT_ROOT = r\"/Volumes/weishanshan/Geo trax tool results/DJI_0031/step5 the result of 1st filter outliers\"\n",
    "PATTERN      = r\"*following_parts*.xlsx\"\n",
    "RECURSIVE    = True\n",
    "\n",
    "# ===================== Tunables =====================\n",
    "SPEED_THRESHOLD_KMH  = 3.6\n",
    "DISTANCE_THRESHOLD_M = 100.0\n",
    "MIN_SEG_DURATION_S   = 3.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "from typing import List, Tuple, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NEEDED_COLS = [\n",
    "    'part','frame_id','time_s',\n",
    "    'follower_uid','leader_uid',\n",
    "    'headway_distance_m','net_headway_distance_m',\n",
    "    'time_headway_s','net_time_headway_s',\n",
    "    'rel_v_kph','rel_a_mps2',\n",
    "    'TTC_s',\n",
    "    'leader_v','leader_a',\n",
    "    'follower_v','follower_a'\n",
    "]\n",
    "\n",
    "DTYPES_NUMERIC_FLOAT32 = [\n",
    "    'time_s','headway_distance_m','net_headway_distance_m',\n",
    "    'time_headway_s','net_time_headway_s',\n",
    "    'rel_v_kph','rel_a_mps2','TTC_s',\n",
    "    'leader_v','leader_a','follower_v','follower_a'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def infer_lane_name(file_path: str, df: pd.DataFrame) -> str:\n",
    "    basename = os.path.basename(file_path)\n",
    "    m = re.search(r'(lane-?\\d+)', basename, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        m = re.search(r'(lane-?\\d+)', file_path, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).lower()\n",
    "    for col in ['lane', 'lane_smoothed', 'lane_name']:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                val = df[col].mode().iloc[0]\n",
    "                return str(val).lower()\n",
    "            except Exception:\n",
    "                pass\n",
    "    return 'lane'\n",
    "\n",
    "\n",
    "def find_valid_segments(group: pd.DataFrame,\n",
    "                        speed_threshold: float = SPEED_THRESHOLD_KMH,\n",
    "                        distance_threshold: float = DISTANCE_THRESHOLD_M,\n",
    "                        min_duration: float = MIN_SEG_DURATION_S) -> List[pd.DataFrame]:\n",
    "    segments: List[pd.DataFrame] = []\n",
    "    current_segment_rows: List[int] = []\n",
    "    prev_frame_id = None\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        cond_speed = row['follower_v'] > speed_threshold\n",
    "        cond_dist  = row['headway_distance_m'] <= distance_threshold\n",
    "        cond = cond_speed and cond_dist\n",
    "        if cond and (prev_frame_id is None or row['frame_id'] == prev_frame_id + 1):\n",
    "            current_segment_rows.append(idx)\n",
    "        else:\n",
    "            if current_segment_rows:\n",
    "                seg = group.loc[current_segment_rows]\n",
    "                duration = seg['time_s'].iloc[-1] - seg['time_s'].iloc[0]\n",
    "                if duration >= min_duration:\n",
    "                    segments.append(seg.copy())\n",
    "                current_segment_rows = []\n",
    "            if cond:\n",
    "                current_segment_rows.append(idx)\n",
    "        prev_frame_id = row['frame_id']\n",
    "\n",
    "    if current_segment_rows:\n",
    "        seg = group.loc[current_segment_rows]\n",
    "        duration = seg['time_s'].iloc[-1] - seg['time_s'].iloc[0]\n",
    "        if duration >= min_duration:\n",
    "            segments.append(seg.copy())\n",
    "    return segments\n",
    "\n",
    "\n",
    "def compute_segment_statistics(segment: pd.DataFrame) -> dict:\n",
    "    metrics = {\n",
    "        'headway_distance_m': segment['headway_distance_m'],\n",
    "        'net_headway_distance_m': segment['net_headway_distance_m'],\n",
    "        'time_headway_s': segment['time_headway_s'],\n",
    "        'net_time_headway_s': segment['net_time_headway_s'],\n",
    "        'rel_v_kph': segment['rel_v_kph'],\n",
    "        'rel_a_mps2': segment['rel_a_mps2'],\n",
    "        'TTC_s': segment['TTC_s'],\n",
    "        'leader_v': segment['leader_v'],\n",
    "        'leader_a': segment['leader_a'],\n",
    "        'follower_v': segment['follower_v'],\n",
    "        'follower_a': segment['follower_a'],\n",
    "    }\n",
    "    out = {}\n",
    "    for name, series in metrics.items():\n",
    "        clean = series.dropna()\n",
    "        out[f'{name}_min']  = clean.min()  if not clean.empty else np.nan\n",
    "        out[f'{name}_max']  = clean.max()  if not clean.empty else np.nan\n",
    "        out[f'{name}_mean'] = clean.mean() if not clean.empty else np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_pair(group: pd.DataFrame, segments: List[pd.DataFrame], out_dir: str, base_name: str,\n",
    "              speed_threshold: float = SPEED_THRESHOLD_KMH,\n",
    "              distance_threshold: float = DISTANCE_THRESHOLD_M,\n",
    "              min_duration: float = MIN_SEG_DURATION_S) -> Tuple[str, str]:\n",
    "    C_FOLLOWER = 'tab:blue'\n",
    "    C_LEADER   = 'tab:orange'\n",
    "    C_THW      = 'tab:green'\n",
    "\n",
    "    follower_kmh = group['follower_v']\n",
    "    leader_kmh   = group['leader_v']\n",
    "    t   = group['time_s']\n",
    "    thw = group['time_headway_s']\n",
    "\n",
    "    valid_mask = (group['follower_v'] > speed_threshold) & (group['headway_distance_m'] <= distance_threshold)\n",
    "    cont_mask  = group['frame_id'].diff().fillna(1) == 1\n",
    "    contiguous_valid = valid_mask & cont_mask\n",
    "    contiguous_valid.iloc[0] = bool(valid_mask.iloc[0])\n",
    "\n",
    "    spans: List[Tuple[int,int,bool]] = []\n",
    "    start = 0\n",
    "    is_valid = bool(contiguous_valid.iloc[0])\n",
    "    for i in range(1, len(group)):\n",
    "        if bool(contiguous_valid.iloc[i]) != is_valid:\n",
    "            spans.append((start, i-1, is_valid))\n",
    "            start = i\n",
    "            is_valid = bool(contiguous_valid.iloc[i])\n",
    "    spans.append((start, len(group)-1, is_valid))\n",
    "\n",
    "    for idx, (s, e, ok) in enumerate(spans):\n",
    "        if ok and (t.iloc[e] - t.iloc[s] < min_duration):\n",
    "            spans[idx] = (s, e, False)\n",
    "\n",
    "    original_path = os.path.join(out_dir, f\"{base_name}_original.png\")\n",
    "    fig = plt.figure(figsize=(9,4))\n",
    "    ax1 = plt.gca()\n",
    "    ax2 = ax1.twinx()\n",
    "    ax1.plot(t, follower_kmh, label='Follower speed', color=C_FOLLOWER, linewidth=1.2)\n",
    "    ax1.plot(t, leader_kmh,   label='Leader speed',   color=C_LEADER,   linewidth=1.2)\n",
    "    ax2.plot(t, thw,          label='Time headway (s)', color=C_THW, linestyle='--', linewidth=1.2)\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Speed (km/h)')\n",
    "    ax2.set_ylabel('Time headway (s)')\n",
    "    ax2.tick_params(axis='y')\n",
    "    for s, e, ok in spans:\n",
    "        if not ok:\n",
    "            color = 'yellow' if bool(valid_mask.iloc[s]) else 'red'\n",
    "            ax1.axvspan(t.iloc[s], t.iloc[e], color=color, alpha=0.3)\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    by_label = {}\n",
    "    for h, lb in zip(lines1 + lines2, labels1 + labels2):\n",
    "        if lb not in by_label:\n",
    "            by_label[lb] = h\n",
    "    ax1.legend(by_label.values(), by_label.keys(), fontsize=7, loc='best')\n",
    "    plt.title(f\"Original: {base_name}\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(original_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    filtered_path = os.path.join(out_dir, f\"{base_name}_1st_filtered.png\")\n",
    "    fig = plt.figure(figsize=(9,4))\n",
    "    ax1 = plt.gca()\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    segment_boundaries = []\n",
    "    first = True\n",
    "    for seg in segments:\n",
    "        t_seg = seg['time_s']\n",
    "        if t_seg.empty:\n",
    "            continue\n",
    "        ax1.plot(t_seg, seg['follower_v'], color='tab:blue', linewidth=1.2,\n",
    "                 label='Follower speed' if first else '_nolegend_')\n",
    "        ax1.plot(t_seg, seg['leader_v'],   color='tab:orange', linewidth=1.2,\n",
    "                 label='Leader speed' if first else '_nolegend_')\n",
    "        ax2.plot(t_seg, seg['time_headway_s'], color='tab:green', linestyle='--', linewidth=1.2,\n",
    "                 label='Time headway (s)' if first else '_nolegend_')\n",
    "\n",
    "        start_t, end_t = t_seg.iloc[0], t_seg.iloc[-1]\n",
    "        segment_boundaries.append((start_t, end_t))\n",
    "\n",
    "        ax1.scatter([start_t, end_t],\n",
    "                    [seg['follower_v'].iloc[0], seg['follower_v'].iloc[-1]],\n",
    "                    marker='o', s=16, color='tab:blue')\n",
    "        ax1.scatter([start_t, end_t],\n",
    "                    [seg['leader_v'].iloc[0],  seg['leader_v'].iloc[-1]],\n",
    "                    marker='o', s=16, color='tab:orange')\n",
    "        ax2.scatter([start_t, end_t],\n",
    "                    [seg['time_headway_s'].iloc[0], seg['time_headway_s'].iloc[-1]],\n",
    "                    marker='o', s=16, color='tab:green')\n",
    "        first = False\n",
    "\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Speed (km/h)')\n",
    "    ax2.set_ylabel('Time headway (s)')\n",
    "    ax2.tick_params(axis='y')\n",
    "    for start_t, end_t in segment_boundaries:\n",
    "        ax1.axvline(start_t, linestyle=':', linewidth=0.8)\n",
    "        ax1.axvline(end_t,   linestyle=':', linewidth=0.8)\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    by_label = {}\n",
    "    for h, lb in zip(lines1 + lines2, labels1 + labels2):\n",
    "        if lb not in by_label:\n",
    "            by_label[lb] = h\n",
    "    ax1.legend(by_label.values(), by_label.keys(), fontsize=7, loc='best')\n",
    "    plt.title(f\"Filtered: {base_name}\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filtered_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return original_path, filtered_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _append_df_csv(df: pd.DataFrame, csv_path: str) -> None:\n",
    "    first = not os.path.exists(csv_path)\n",
    "    df.to_csv(csv_path, mode='a', header=first, index=False)\n",
    "\n",
    "def _append_dict_csv(row: dict, csv_path: str) -> None:\n",
    "    first = not os.path.exists(csv_path)\n",
    "    pd.DataFrame([row]).to_csv(csv_path, mode='a', header=first, index=False)\n",
    "\n",
    "def process_dataset(file_path: str,\n",
    "                    output_root: str,\n",
    "                    speed_threshold: float = SPEED_THRESHOLD_KMH,\n",
    "                    distance_threshold: float = DISTANCE_THRESHOLD_M,\n",
    "                    min_duration: float = MIN_SEG_DURATION_S) -> None:\n",
    "    df = pd.read_excel(file_path, sheet_name=0, usecols=lambda c: c in set(NEEDED_COLS))\n",
    "\n",
    "    if 'part' in df.columns:\n",
    "        try:\n",
    "            df['part'] = pd.to_numeric(df['part'], errors='coerce').fillna(-1).astype('int16')\n",
    "        except Exception:\n",
    "            df['part'] = df['part'].astype(str)\n",
    "    if 'frame_id' in df.columns:\n",
    "        df['frame_id'] = pd.to_numeric(df['frame_id'], errors='coerce').astype('Int64').astype('float64')\n",
    "    for col in DTYPES_NUMERIC_FLOAT32:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
    "    for col in ['follower_uid','leader_uid']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    lane_name = infer_lane_name(file_path, df)\n",
    "    file_stub = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    parts = sorted(pd.unique(df['part'])) if 'part' in df.columns else [0]\n",
    "\n",
    "    for part in parts:\n",
    "        part_df = df[df['part'] == part].copy() if 'part' in df.columns else df.copy()\n",
    "        part_df.sort_values(['follower_uid','leader_uid','frame_id'], inplace=True)\n",
    "\n",
    "        part_dir = os.path.join(output_root, f\"{lane_name}_{file_stub}_part{part}\")\n",
    "        filtered_plots_dir  = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_1st_filtered_plots\")\n",
    "        original_plots_dir  = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_original_plots\")\n",
    "        os.makedirs(filtered_plots_dir, exist_ok=True)\n",
    "        os.makedirs(original_plots_dir, exist_ok=True)\n",
    "\n",
    "        seg_csv_path   = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_1st_filtered_data.csv\")\n",
    "        summ_csv_path  = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_1st_segment_summary.csv\")\n",
    "        for p in [seg_csv_path, summ_csv_path]:\n",
    "            if os.path.exists(p):\n",
    "                os.remove(p)\n",
    "\n",
    "        for (follower, leader), group in part_df.groupby(['follower_uid','leader_uid'], sort=False):\n",
    "            group_sorted = group.sort_values('frame_id').reset_index(drop=True)\n",
    "\n",
    "            segments = find_valid_segments(group_sorted,\n",
    "                                           speed_threshold=speed_threshold,\n",
    "                                           distance_threshold=distance_threshold,\n",
    "                                           min_duration=min_duration)\n",
    "            if not segments:\n",
    "                del group_sorted\n",
    "                continue\n",
    "\n",
    "            for seg_id, seg in enumerate(segments, start=1):\n",
    "                seg = seg.copy()\n",
    "                seg['segment_id']   = seg_id\n",
    "                seg['part']         = part\n",
    "                _append_df_csv(seg, seg_csv_path)\n",
    "                stats = compute_segment_statistics(seg)\n",
    "                _append_dict_csv({\n",
    "                    'segment_id': seg_id,\n",
    "                    'part': part,\n",
    "                    'follower_uid': follower,\n",
    "                    'leader_uid': leader,\n",
    "                    **stats\n",
    "                }, summ_csv_path)\n",
    "                del seg\n",
    "\n",
    "            base_name = f\"{lane_name}_{file_stub}_part{part}_{follower}_{leader}\"\n",
    "            orig_path, filt_path = plot_pair(group_sorted, segments, original_plots_dir, base_name,\n",
    "                                             speed_threshold=speed_threshold,\n",
    "                                             distance_threshold=distance_threshold,\n",
    "                                             min_duration=min_duration)\n",
    "            os.replace(filt_path, os.path.join(filtered_plots_dir, os.path.basename(filt_path)))\n",
    "            del group_sorted, segments\n",
    "            gc.collect()\n",
    "\n",
    "        del part_df\n",
    "        gc.collect()\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def _expand_inputs(paths_or_dirs: Iterable[str], pattern: str, recursive: bool=True) -> List[str]:\n",
    "    found = []\n",
    "    for p in paths_or_dirs:\n",
    "        if os.path.isfile(p) and p.lower().endswith('.xlsx'):\n",
    "            found.append(p)\n",
    "        elif os.path.isdir(p):\n",
    "            glob_pat = os.path.join(p, '**', pattern) if recursive else os.path.join(p, pattern)\n",
    "            found.extend(glob.glob(glob_pat, recursive=recursive))\n",
    "        else:\n",
    "            found.extend(glob.glob(p, recursive=recursive))\n",
    "    found = sorted(list(dict.fromkeys(found)))\n",
    "    return found\n",
    "\n",
    "\n",
    "def process_many(paths_or_dirs: Iterable[str],\n",
    "                 output_root: str,\n",
    "                 pattern: str = '*following_parts*.xlsx',\n",
    "                 recursive: bool = True,\n",
    "                 speed_threshold: float = SPEED_THRESHOLD_KMH,\n",
    "                 distance_threshold: float = DISTANCE_THRESHOLD_M,\n",
    "                 min_duration: float = MIN_SEG_DURATION_S) -> None:\n",
    "    files = _expand_inputs(paths_or_dirs, pattern=pattern, recursive=recursive)\n",
    "    if not files:\n",
    "        print(f\"[WARN] No files matched. Inputs={paths_or_dirs}, pattern='{pattern}'\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    print(f\"[INFO] Found {len(files)} files to process.\")\n",
    "    for i, f in enumerate(files, 1):\n",
    "        print(f\"[{i}/{len(files)}] Processing: {f}\")\n",
    "        try:\n",
    "            process_dataset(f, output_root=output_root,\n",
    "                            speed_threshold=speed_threshold,\n",
    "                            distance_threshold=distance_threshold,\n",
    "                            min_duration=min_duration)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed on {f}: {e}\")\n",
    "        gc.collect()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# ===================== Run =====================\n",
    "process_many(paths_or_dirs=INPUTS,\n",
    "             output_root=OUTPUT_ROOT,\n",
    "             pattern=PATTERN,\n",
    "             recursive=RECURSIVE,\n",
    "             speed_threshold=SPEED_THRESHOLD_KMH,\n",
    "             distance_threshold=DISTANCE_THRESHOLD_M,\n",
    "             min_duration=MIN_SEG_DURATION_S)\n",
    "\n",
    "print(\"[DONE] All processing completed.\")\n",
    "print(\"Output root:\", OUTPUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f5fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
